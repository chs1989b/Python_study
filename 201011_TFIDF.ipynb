{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.TF-IDF 개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = ['I go to my home my home is very large', \n",
    "       'I went out my home I go to the market', \n",
    "       'I bought a yellow lemon I go back to home']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I go to my home my home is very large',\n",
       " 'I went out my home I go to the market',\n",
       " 'I bought a yellow lemon I go back to home']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('back', 0),\n",
       " ('bought', 1),\n",
       " ('go', 2),\n",
       " ('home', 3),\n",
       " ('is', 4),\n",
       " ('large', 5),\n",
       " ('lemon', 6),\n",
       " ('market', 7),\n",
       " ('my', 8),\n",
       " ('out', 9),\n",
       " ('the', 10),\n",
       " ('to', 11),\n",
       " ('very', 12),\n",
       " ('went', 13),\n",
       " ('yellow', 14)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text)\n",
    "tfidf_vectorizer.vocabulary_\n",
    "sorted(tfidf_vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TF, DF, IDF 벡터화과정의 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.        , 1.        , 1.69314718,\n",
       "       1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718, 1.69314718, 1.69314718])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2170186 , 0.4340372 , 0.36744443,\n",
       "        0.36744443, 0.        , 0.        , 0.55890191, 0.        ,\n",
       "        0.        , 0.2170186 , 0.36744443, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.24902824, 0.24902824, 0.        ,\n",
       "        0.        , 0.        , 0.42164146, 0.3206692 , 0.42164146,\n",
       "        0.42164146, 0.24902824, 0.        , 0.42164146, 0.        ],\n",
       "       [0.44514923, 0.44514923, 0.26291231, 0.26291231, 0.        ,\n",
       "        0.        , 0.44514923, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26291231, 0.        , 0.        , 0.44514923]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. IDF 벡터화 해부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.        , 1.        , 1.69314718,\n",
       "       1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718, 1.69314718, 1.69314718])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DF_vec = np.array([1,1,3,3,1,\n",
    "                  1,1,1,2,1,\n",
    "                  1,3,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_func(n, df):\n",
    "    rst = np.log((1+n)/(1+df))+1\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.        , 1.        , 1.69314718,\n",
       "       1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718, 1.69314718, 1.69314718])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3은 문서의 갯수\n",
    "idf_func(3, DF_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. TF-IDF 벡터화 해부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2170186 , 0.4340372 , 0.36744443,\n",
       "        0.36744443, 0.        , 0.        , 0.55890191, 0.        ,\n",
       "        0.        , 0.2170186 , 0.36744443, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.24902824, 0.24902824, 0.        ,\n",
       "        0.        , 0.        , 0.42164146, 0.3206692 , 0.42164146,\n",
       "        0.42164146, 0.24902824, 0.        , 0.42164146, 0.        ],\n",
       "       [0.44514923, 0.44514923, 0.26291231, 0.26291231, 0.        ,\n",
       "        0.        , 0.44514923, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26291231, 0.        , 0.        , 0.44514923]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25분\n",
    "tfidf_vectorizer.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = np.array([0,0,1,2,1,\n",
    "                      1,0,0,2,0,\n",
    "                      0,1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.        , 1.        , 1.69314718,\n",
       "       1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718, 1.69314718, 1.69314718])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 1.        , 2.        , 1.69314718,\n",
       "       1.69314718, 0.        , 0.        , 2.57536414, 0.        ,\n",
       "       0.        , 1.        , 1.69314718, 0.        , 0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(count_vec, tfidf_vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2170186 , 0.4340372 , 0.36744443,\n",
       "        0.36744443, 0.        , 0.        , 0.55890191, 0.        ,\n",
       "        0.        , 0.2170186 , 0.36744443, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "tf_idf_before_l2 = np.multiply(count_vec, tfidf_vectorizer.idf_)\n",
    "tf_idf_before_l2 = tf_idf_before_l2.reshape(1, -1)\n",
    "tf_idf_after_l2 = preprocessing.normalize(tf_idf_before_l2, norm='l2')\n",
    "tf_idf_after_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.2170186 , 0.4340372 , 0.36744443,\n",
       "       0.36744443, 0.        , 0.        , 0.55890191, 0.        ,\n",
       "       0.        , 0.2170186 , 0.36744443, 0.        , 0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.transform(text).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
